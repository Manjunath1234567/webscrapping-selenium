{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required libraries for web scraping assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox('E:\\geckodriver-v0.29.1-win64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st question"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Specify Serach Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we see the wiki website for the provided url the required data to scrap is in table format. \n",
    "#So we will first scrap the whole required table with Beautiful soup. \n",
    "#From the scrapped data we will make the required changes for exact data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html')\n",
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will load the data with pandas.read_htnl(because it is in html format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the len(df) we can see that nearly 12 tables are scrapped from the provided wiki page. \n",
    "#with the help of index we can find the exact table we required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Video name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views (billions)</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Note</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>8.78</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>[B]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.40</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>[C]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[25]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5.46</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>[D]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.35</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>[E]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.14</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>[F]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  No.                  Video name                        Uploader  \\\n",
       "0  1.      \"Baby Shark Dance\"[22]  Pinkfong Kids' Songs & Stories   \n",
       "1  2.             \"Despacito\"[24]                      Luis Fonsi   \n",
       "2  3.  \"Johny Johny Yes Papa\"[25]                     LooLoo Kids   \n",
       "3  4.          \"Shape of You\"[26]                      Ed Sheeran   \n",
       "4  5.         \"See You Again\"[27]                     Wiz Khalifa   \n",
       "\n",
       "  Views (billions)       Upload date Note Unnamed: 6  \n",
       "0             8.78     June 17, 2016  [B]        NaN  \n",
       "1             7.40  January 12, 2017  [C]        NaN  \n",
       "2             5.46   October 8, 2016  [D]        NaN  \n",
       "3             5.35  January 30, 2017  [E]        NaN  \n",
       "4             5.14     April 6, 2015  [F]        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we got the required table from the second table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you see the wiki website the table contains information of 30 rows.\n",
    "#But with the df.shape we can see that 31 rows are included. So we will do slicing to get 30 songs list.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No.', 'Video name', 'Uploader', 'Views (billions)', 'Upload date',\n",
       "       'Note', 'Unnamed: 6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As per the given question we don't need 'Note','Unnamed: 6 columns. So we will drop them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns =['Note','Unnamed: 6'] , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will replace the columns names 'No' with 'Rank' and 'Uploader'as artist.\n",
    "#I did this because the artist name is in uploader columns and the songs listed in correct order. So I use S.no as rank.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'No.':'Rank'}, inplace = True)\n",
    "df.rename(columns = {'Uploader':'Artist'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the VideoName column there is extra characters which we don't need with the help of regex we will remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Video name']=df['Video name'].replace('\\\"','',regex=True).astype(object)\n",
    "df['Video name']=df['Video name'].replace('\\[\\d{2}\\]','',regex=True).astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will get required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (billions)</th>\n",
       "      <th>Upload date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>8.78</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.40</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5.46</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.35</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.14</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.44</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.20</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.15</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.14</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.09</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>3.92</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.48</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.44</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.39</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.37</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.32</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.27</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.09</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.08</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.08</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.07</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.05</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.05</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.04</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.01</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>2.93</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2.87</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>2.85</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Adele</td>\n",
       "      <td>2.84</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>2.83</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                 Video name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                               Shape of You   \n",
       "4    5.                              See You Again   \n",
       "5    6.   Masha and the Bear – Recipe for Disaster   \n",
       "6    7.                                Uptown Funk   \n",
       "7    8.  Learning Colors – Colorful Eggs on a Farm   \n",
       "8    9.                                  Bath Song   \n",
       "9   10.                              Gangnam Style   \n",
       "10  11.                Phonics Song with Two Words   \n",
       "11  12.                                      Sugar   \n",
       "12  13.                                      Sorry   \n",
       "13  14.                             Dame Tu Cosita   \n",
       "14  15.                                       Roar   \n",
       "15  16.                             Counting Stars   \n",
       "16  17.                          Thinking Out Loud   \n",
       "17  18.                                 Dark Horse   \n",
       "18  19.                                      Faded   \n",
       "19  20.                          Wheels on the Bus   \n",
       "20  21.                               Shake It Off   \n",
       "21  22.                                    Lean On   \n",
       "22  23.                             Girls Like You   \n",
       "23  24.                                   Bailando   \n",
       "24  25.                                 Let Her Go   \n",
       "25  26.                                   Mi Gente   \n",
       "26  27.                                    Perfect   \n",
       "27  28.           Waka Waka (This Time for Africa)   \n",
       "28  29.                                      Hello   \n",
       "29  30.                                     Axel F   \n",
       "\n",
       "                            Artist Views (billions)        Upload date  \n",
       "0   Pinkfong Kids' Songs & Stories             8.78      June 17, 2016  \n",
       "1                       Luis Fonsi             7.40   January 12, 2017  \n",
       "2                      LooLoo Kids             5.46    October 8, 2016  \n",
       "3                       Ed Sheeran             5.35   January 30, 2017  \n",
       "4                      Wiz Khalifa             5.14      April 6, 2015  \n",
       "5                       Get Movies             4.44   January 31, 2012  \n",
       "6                      Mark Ronson             4.20  November 19, 2014  \n",
       "7                      Miroshka TV             4.15  February 27, 2018  \n",
       "8       Cocomelon – Nursery Rhymes             4.14        May 2, 2018  \n",
       "9                              Psy             4.09      July 15, 2012  \n",
       "10                       ChuChu TV             3.92      March 6, 2014  \n",
       "11                        Maroon 5             3.48   January 14, 2015  \n",
       "12                   Justin Bieber             3.44   October 22, 2015  \n",
       "13                       El Chombo             3.39      April 5, 2018  \n",
       "14                      Katy Perry             3.37  September 5, 2013  \n",
       "15                     OneRepublic             3.32       May 31, 2013  \n",
       "16                      Ed Sheeran             3.27    October 7, 2014  \n",
       "17                      Katy Perry             3.09  February 20, 2014  \n",
       "18                     Alan Walker             3.08   December 3, 2015  \n",
       "19      Cocomelon – Nursery Rhymes             3.08       May 24, 2018  \n",
       "20                    Taylor Swift             3.07    August 18, 2014  \n",
       "21                     Major Lazer             3.05     March 22, 2015  \n",
       "22                        Maroon 5             3.05       May 31, 2018  \n",
       "23                Enrique Iglesias             3.04     April 11, 2014  \n",
       "24                       Passenger             3.01      July 25, 2012  \n",
       "25                        J Balvin             2.93      June 29, 2017  \n",
       "26                      Ed Sheeran             2.87   November 9, 2017  \n",
       "27                         Shakira             2.85       June 4, 2010  \n",
       "28                           Adele             2.84   October 22, 2015  \n",
       "29                      Crazy Frog             2.83      June 16, 2009  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd Question"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify serach URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now from the International Option we will select Fixtures with click() option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will select international option.From that we will see drop down to select Fixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inte=driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inte.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will select fixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix=driver.find_element_by_xpath(\"//div[@class='drop-down__options']/ul/li[1]/a[1]\")\n",
    "fix.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will Scrap the required data. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Match title (I.e. 1st ODI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/strong\")\n",
    "Match_title=[]\n",
    "for i in mat:\n",
    "    Match_title.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser=driver.find_elements_by_xpath(\"//div[@class='fixture__format-strip']/span[2]\")\n",
    "Series=[]\n",
    "for i in ser:\n",
    "    Series.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ple=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "Places=[]\n",
    "for i in ple:\n",
    "    Places.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim=driver.find_elements_by_xpath(\"//div[@class='fixture__date-details']/span[2]\")\n",
    "Time=[]\n",
    "for i in tim:\n",
    "    Time.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=driver.find_elements_by_xpath(\"//span[@class='fixture__date']\")\n",
    "Date=[]\n",
    "for i in dat:\n",
    "    Date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we check the website the date and month have different xpaths. So First we scrapped Date and  now we will scrap month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon=driver.find_elements_by_xpath(\"//div[@class='fixture__date-details']/span[1]\")\n",
    "Month=[]\n",
    "for i in mon:\n",
    "    Month.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating data frame for the scrapped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Places</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP</td>\n",
       "      <td>The Ageas Bowl, Southampton</td>\n",
       "      <td>18</td>\n",
       "      <td>JUNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>13</td>\n",
       "      <td>JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>16</td>\n",
       "      <td>JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>18</td>\n",
       "      <td>JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>21</td>\n",
       "      <td>JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>23</td>\n",
       "      <td>JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>25</td>\n",
       "      <td>JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04</td>\n",
       "      <td>AUGUST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>12</td>\n",
       "      <td>AUGUST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>25</td>\n",
       "      <td>AUGUST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>02</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>10</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_Title                       Series                        Places  \\\n",
       "0        Final  ICC WORLD TEST CHAMPIONSHIP   The Ageas Bowl, Southampton   \n",
       "1      1st ODI       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "2      2nd ODI       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "3      3rd ODI       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "4     1st T20I       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "5     2nd T20I       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "6     3rd T20I       SRI LANKA V INDIA 2021  R Premadasa Stadium, Colombo   \n",
       "7     1st Test         ENGLAND V INDIA 2021      Trent Bridge, Nottingham   \n",
       "8     2nd Test         ENGLAND V INDIA 2021                Lord's, London   \n",
       "9     3rd Test         ENGLAND V INDIA 2021             Headingley, Leeds   \n",
       "10    4th Test         ENGLAND V INDIA 2021              The Oval, London   \n",
       "11    5th Test         ENGLAND V INDIA 2021      Old Trafford, Manchester   \n",
       "\n",
       "   Date      Month  \n",
       "0    18       JUNE  \n",
       "1    13       JULY  \n",
       "2    16       JULY  \n",
       "3    18       JULY  \n",
       "4    21       JULY  \n",
       "5    23       JULY  \n",
       "6    25       JULY  \n",
       "7    04     AUGUST  \n",
       "8    12     AUGUST  \n",
       "9    25     AUGUST  \n",
       "10   02  SEPTEMBER  \n",
       "11   10  SEPTEMBER  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcci=pd.DataFrame({})\n",
    "bcci['Match_Title']=Match_title\n",
    "bcci['Series']=Series\n",
    "bcci['Places']=Places\n",
    "bcci['Date']=Date\n",
    "bcci['Month']=Month\n",
    "bcci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd Question"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify Search URl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.guru99.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the home page we have to reach to 'selenium exception handling page' for that we will use the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On the home page there are various programmes listed we will select Selenium option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec=driver.find_element_by_xpath(\"//div[@class='srch']/span[8]/a\")\n",
    "sec.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now in this page there is Syllabus of Selenium in this we will select 'exception handling page'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "se=driver.find_element_by_xpath(\"//table[@class='table'][5]/tbody/tr[34]/td[1]\")\n",
    "se.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we got the exact page where we can scrap the required data.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\")\n",
    "Name=[]\n",
    "for i in exc:\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "des=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\")\n",
    "Description=[]\n",
    "for i in des:\n",
    "    Description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will create DataFrame for the scrapped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selenium_exception=pd.DataFrame({})\n",
    "Selenium_exception[\"Name\"]=Name\n",
    "Selenium_exception[\"Description\"]=Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exception name</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name  \\\n",
       "0                 Exception name   \n",
       "1     ElementNotVisibleException   \n",
       "2  ElementNotSelectableException   \n",
       "3         NoSuchElementException   \n",
       "4           NoSuchFrameException   \n",
       "\n",
       "                                         Description  \n",
       "0                                        Description  \n",
       "1  This type of Selenium exception occurs when an...  \n",
       "2  This Selenium exception occurs when an element...  \n",
       "3  This Exception occurs if an element could not ...  \n",
       "4  This Exception occurs if the frame target to b...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selenium_exception.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we scrapped data we got the heading of table also because even heading has same xpaths. So we will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selenium_exception.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selenium_exception=Selenium_exception[1:42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name  \\\n",
       "1            ElementNotVisibleException   \n",
       "2         ElementNotSelectableException   \n",
       "3                NoSuchElementException   \n",
       "4                  NoSuchFrameException   \n",
       "5               NoAlertPresentException   \n",
       "6                 NoSuchWindowException   \n",
       "7        StaleElementReferenceException   \n",
       "8              SessionNotFoundException   \n",
       "9                      TimeoutException   \n",
       "10                   WebDriverException   \n",
       "11            ConnectionClosedException   \n",
       "12     ElementClickInterceptedException   \n",
       "13      ElementNotInteractableException   \n",
       "14             ErrorInResponseException   \n",
       "15  ErrorHandler.UnknownServerException   \n",
       "16         ImeActivationFailedException   \n",
       "17             ImeNotAvailableException   \n",
       "18         InsecureCertificateException   \n",
       "19             InvalidArgumentException   \n",
       "20         InvalidCookieDomainException   \n",
       "21          InvalidCoordinatesException   \n",
       "22          InvalidElementStateExceptio   \n",
       "23            InvalidSessionIdException   \n",
       "24       InvalidSwitchToTargetException   \n",
       "25                  JavascriptException   \n",
       "26                        JsonException   \n",
       "27             NoSuchAttributeException   \n",
       "28       MoveTargetOutOfBoundsException   \n",
       "29               NoSuchContextException   \n",
       "30                NoSuchCookieException   \n",
       "31                    NotFoundException   \n",
       "32          RemoteDriverServerException   \n",
       "33                  ScreenshotException   \n",
       "34           SessionNotCreatedException   \n",
       "35           UnableToSetCookieException   \n",
       "36           UnexpectedTagNameException   \n",
       "37              UnhandledAlertException   \n",
       "38      UnexpectedAlertPresentException   \n",
       "39               UnknownMethodException   \n",
       "40          UnreachableBrowserException   \n",
       "41          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "1   This type of Selenium exception occurs when an...  \n",
       "2   This Selenium exception occurs when an element...  \n",
       "3   This Exception occurs if an element could not ...  \n",
       "4   This Exception occurs if the frame target to b...  \n",
       "5   This Exception occurs when you switch to no pr...  \n",
       "6   This Exception occurs if the window target to ...  \n",
       "7   This Selenium exception occurs happens when th...  \n",
       "8   The WebDriver is acting after you quit the bro...  \n",
       "9   Thrown when there is not enough time for a com...  \n",
       "10  This Exception takes place when the WebDriver ...  \n",
       "11  This type of Exception takes place when there ...  \n",
       "12  The command may not be completed as the elemen...  \n",
       "13  This Selenium exception is thrown when any ele...  \n",
       "14  This happens while interacting with the Firefo...  \n",
       "15  Exception is used as a placeholder in case if ...  \n",
       "16  This expectation will occur when IME engine ac...  \n",
       "17    It takes place when IME support is unavailable.  \n",
       "18  Navigation made the user agent to hit a certif...  \n",
       "19  It occurs when an argument does not belong to ...  \n",
       "20  This happens when you try to add a cookie unde...  \n",
       "21  This type of Exception matches an interacting ...  \n",
       "22  It occurs when command can't be finished when ...  \n",
       "23  This Exception took place when the given sessi...  \n",
       "24  This occurs when the frame or window target to...  \n",
       "25  This issue occurs while executing JavaScript g...  \n",
       "26  It occurs when you afford to get the session w...  \n",
       "27  This kind of Exception occurs when the attribu...  \n",
       "28  It takes place if the target provided to the A...  \n",
       "29           ContextAware does mobile device testing.  \n",
       "30  This Exception occurs when no cookie matching ...  \n",
       "31  This Exception is a subclass of WebDriverExcep...  \n",
       "32  This Selenium exception is thrown when the ser...  \n",
       "33            It is not possible to capture a screen.  \n",
       "34  It happens when a new session could not be suc...  \n",
       "35  This occurs if a driver is unable to set a coo...  \n",
       "36  Happens if a support class did not get a web e...  \n",
       "37  This expectation occurs when there is an alert...  \n",
       "38  It occurs when there is the appearance of an u...  \n",
       "39  This Exception happens when the requested comm...  \n",
       "40  This Exception occurs only when the browser is...  \n",
       "41  This occurs when remote WebDriver does n't sen...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selenium_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th Question"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify search url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the home page we have to select Economy and Inida option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see that Economy option is not clickable, we have to do mouseover action .  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ActionChains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can perform mouseover action in Selenium webdriver in Python by using the ActionChains class. \n",
    "#We have to create an object of this class and then apply suitable methods on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to move the mouse to an element, we shall use the move_to_element method and pass the element locator as a parameter. \n",
    "#Then apply the perform method to actually perform this action. After hovering on the element, we can apply click action on it with the help of the click method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ActionChains Required Library\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object of ActionChains\n",
    "a = ActionChains(driver)\n",
    "#identify element\n",
    "m = driver.find_element_by_xpath(\"//div[@class='navbar']/div[2]/button\")\n",
    "#hover over element\n",
    "a.move_to_element(m).perform()\n",
    "#identify sub menu element\n",
    "n = driver.find_element_by_link_text(\"India\")\n",
    "# hover over element and click\n",
    "a.move_to_element(n).click().perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need state wise GDP. So we will select \"GDP of Indian States. With click() option.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//ul[@style='list-style-type:none;margin-left:20px;']/li[1]/a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will scrap the required data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra=driver.find_elements_by_xpath(\"//div[@class='fwidth'][3]/div/div/table/tbody/tr/td[1]\")\n",
    "Rank=[]\n",
    "for i in ra:\n",
    "    Rank.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa=driver.find_elements_by_xpath(\"//div[@class='fwidth'][3]/div/div/table/tbody/tr/td[2]\")\n",
    "State=[]\n",
    "for i in sa:\n",
    "    State.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GSDP(17-18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsd=driver.find_elements_by_xpath(\"//div[@class='fwidth'][3]/div/div/table/tbody/tr/td[4]\")\n",
    "GSDP_17_18=[]\n",
    "for i in gsd:\n",
    "    GSDP_17_18.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GSDP(18-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=driver.find_elements_by_xpath(\"//div[@class='fwidth'][3]/div/div/table/tbody/tr/td[3]\")\n",
    "GSDP_18_19=[]\n",
    "for i in gs:\n",
    "    GSDP_18_19.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Share(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sha=driver.find_elements_by_xpath(\"//div[@class='fwidth'][3]/div/div/table/tbody/tr/td[5]\")\n",
    "Share=[]\n",
    "for i in sha:\n",
    "    Share.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bil=driver.find_elements_by_xpath(\"//div[@class='fwidth'][3]/div/div/table/tbody/tr/td[6]\")\n",
    "GDP_billions=[]\n",
    "for i in bil:\n",
    "    GDP_billions.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the data frame for the scrapped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_17_18</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP_billions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP_17_18 GSDP_18_19   Share GDP_billions\n",
       "0     1                Maharashtra  2,632,792          -  13.94%      399.921\n",
       "1     2                 Tamil Nadu  1,630,208  1,845,853   8.63%      247.629\n",
       "2     3              Uttar Pradesh  1,584,764  1,687,818   8.39%      240.726\n",
       "3     4                    Gujarat  1,502,899          -   7.96%      228.290\n",
       "4     5                  Karnataka  1,493,127  1,631,977   7.91%      226.806\n",
       "5     6                West Bengal  1,089,898  1,253,832   5.77%      165.556\n",
       "6     7                  Rajasthan    942,586  1,020,989   4.99%      143.179\n",
       "7     8             Andhra Pradesh    862,957    972,782   4.57%      131.083\n",
       "8     9                  Telangana    861,031    969,604   4.56%      130.791\n",
       "9    10             Madhya Pradesh    809,592    906,672   4.29%      122.977\n",
       "10   11                     Kerala    781,653          -   4.14%      118.733\n",
       "11   12                      Delhi    774,870    856,112   4.10%      117.703\n",
       "12   13                    Haryana    734,163    831,610   3.89%      111.519\n",
       "13   14                      Bihar    530,363    611,804   2.81%       80.562\n",
       "14   15                     Punjab    526,376    574,760   2.79%       79.957\n",
       "15   16                     Odisha    487,805    521,275   2.58%       74.098\n",
       "16   17                      Assam    315,881          -   1.67%       47.982\n",
       "17   18               Chhattisgarh    304,063    329,180   1.61%       46.187\n",
       "18   19                  Jharkhand    297,204    328,598   1.57%       45.145\n",
       "19   20                Uttarakhand    245,895          -   1.30%       37.351\n",
       "20   21            Jammu & Kashmir    155,956          -   0.83%       23.690\n",
       "21   22           Himachal Pradesh    153,845    165,472   0.81%       23.369\n",
       "22   23                        Goa     73,170     80,449   0.39%       11.115\n",
       "23   24                    Tripura     49,845     55,984   0.26%        7.571\n",
       "24   25                 Chandigarh     42,114          -   0.22%        6.397\n",
       "25   26                 Puducherry     34,433     38,253   0.18%        5.230\n",
       "26   27                  Meghalaya     33,481     36,572   0.18%        5.086\n",
       "27   28                     Sikkim     28,723     32,496   0.15%        4.363\n",
       "28   29                    Manipur     27,870     31,790   0.15%        4.233\n",
       "29   30                   Nagaland     27,283          -   0.14%        4.144\n",
       "30   31          Arunachal Pradesh     24,603          -   0.13%        3.737\n",
       "31   32                    Mizoram     22,287     26,503   0.12%        3.385\n",
       "32   33  Andaman & Nicobar Islands          -          -       -            -"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Economy=pd.DataFrame({})\n",
    "Economy['Rank']=Rank\n",
    "Economy['State']=State\n",
    "Economy['GSDP_17_18']=GSDP_17_18\n",
    "Economy['GSDP_18_19']=GSDP_18_19\n",
    "Economy['Share']=Share\n",
    "Economy['GDP_billions']=GDP_billions\n",
    "Economy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5th Question. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify search url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the home page we have to click on the trending option from Explore menu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will select Explore menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "se=driver.find_element_by_xpath(\"//ul[@class='d-lg-flex list-style-none']/li[4]\")\n",
    "se.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will select Trending option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "trending=driver.find_element_by_xpath(\"//ul[@class='list-style-none mb-3']/li[3]\")\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will get urls with attribute href for the trending repositires to scrap the required data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]\n",
    "for j in driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\"):\n",
    "    urls.append(j.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now with the help of urls we will scrap the required data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        title=driver.find_element_by_xpath(\"//h1[@class=' d-flex flex-wrap flex-items-center break-word f3 text-normal']/strong/a\")\n",
    "        Repository_title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append(\"-\")\n",
    "    try:\n",
    "        description=driver.find_element_by_xpath(\"//p[@class='f4 mt-3']\")\n",
    "        Repository_description.append(description.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append(\"-\")      \n",
    "        \n",
    "    try:\n",
    "        count=driver.find_element_by_xpath(\"(//h2[@class='h4 mb-3']/a/span)[3]\")\n",
    "        Contributors_count.append(count.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_count.append(\"-\")\n",
    "    try:\n",
    "        language=driver.find_element_by_xpath(\"//span[@class='color-text-primary text-bold mr-1']\")\n",
    "        Language_used.append(language.text)\n",
    "    except NoSuchElementException:\n",
    "        Language_used.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(Language_used),len(Contributors_count),len(Repository_description),len(Repository_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will create a dataframe for the scrapped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nushell</td>\n",
       "      <td>A new type of shell</td>\n",
       "      <td>232</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thanos</td>\n",
       "      <td>Highly available Prometheus setup with long te...</td>\n",
       "      <td>8</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>keras</td>\n",
       "      <td>Deep Learning for humans</td>\n",
       "      <td>882</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>next.js</td>\n",
       "      <td>The React Framework</td>\n",
       "      <td>322k</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chromium</td>\n",
       "      <td>The official GitHub mirror of the Chromium source</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fully-homomorphic-encryption</td>\n",
       "      <td>Libraries and tools to perform fully homomorph...</td>\n",
       "      <td>-</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The-Complete-FAANG-Preparation</td>\n",
       "      <td>This repository contains all the DSA (Data-Str...</td>\n",
       "      <td>-</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>books</td>\n",
       "      <td>【编程随想】收藏的电子书清单（多个学科，含下载链接）</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MalwareSourceCode</td>\n",
       "      <td>Collection of malware source code for a variet...</td>\n",
       "      <td>-</td>\n",
       "      <td>Assembly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>monyhar-lite</td>\n",
       "      <td>梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...</td>\n",
       "      <td>-</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>javascript-questions</td>\n",
       "      <td>A long list of (advanced) JavaScript questions...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>modern-unix</td>\n",
       "      <td>A collection of modern/faster/saner alternativ...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30-Days-Of-JavaScript</td>\n",
       "      <td>30 days of JavaScript programming challenge is...</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Microsoft-Activation-Scripts</td>\n",
       "      <td>A collection of scripts for activating Microso...</td>\n",
       "      <td>-</td>\n",
       "      <td>Batchfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the-book-of-secret-knowledge</td>\n",
       "      <td>A collection of inspiring lists, manuals, chea...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SimSwap</td>\n",
       "      <td>The official project of SimSwap (ACM MM 2020)</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>zhao</td>\n",
       "      <td>【编程随想】整理的《太子党关系网络》，专门揭露赵国的权贵</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jina</td>\n",
       "      <td>Cloud-Native Neural Search Framework for Any K...</td>\n",
       "      <td>97</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>turbo-rails</td>\n",
       "      <td>Use Turbo in your Ruby on Rails app</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>seata</td>\n",
       "      <td>Seata is an easy-to-use, high-performance, ope...</td>\n",
       "      <td>161</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>allennlp</td>\n",
       "      <td>An open-source NLP research library, built on ...</td>\n",
       "      <td>238</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NvChad</td>\n",
       "      <td>beautiful neovim setup configured in lua</td>\n",
       "      <td>-</td>\n",
       "      <td>Lua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AspNetCore.Docs</td>\n",
       "      <td>Documentation for ASP.NET Core</td>\n",
       "      <td>1,421</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pytorch-tutorial</td>\n",
       "      <td>PyTorch Tutorial for Deep Learning Researchers</td>\n",
       "      <td>-</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Smart-Inspector</td>\n",
       "      <td>Keeps your screen real-estate clean with refin...</td>\n",
       "      <td>-</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Repository_title  \\\n",
       "0                          nushell   \n",
       "1                           thanos   \n",
       "2                            keras   \n",
       "3                          next.js   \n",
       "4                         chromium   \n",
       "5     fully-homomorphic-encryption   \n",
       "6   The-Complete-FAANG-Preparation   \n",
       "7                            books   \n",
       "8                MalwareSourceCode   \n",
       "9                     monyhar-lite   \n",
       "10            javascript-questions   \n",
       "11                     modern-unix   \n",
       "12           30-Days-Of-JavaScript   \n",
       "13    Microsoft-Activation-Scripts   \n",
       "14    the-book-of-secret-knowledge   \n",
       "15                         SimSwap   \n",
       "16                            zhao   \n",
       "17                            jina   \n",
       "18                     turbo-rails   \n",
       "19                           seata   \n",
       "20                        allennlp   \n",
       "21                          NvChad   \n",
       "22                 AspNetCore.Docs   \n",
       "23                pytorch-tutorial   \n",
       "24                 Smart-Inspector   \n",
       "\n",
       "                               Repository_description Contributors_count  \\\n",
       "0                                 A new type of shell                232   \n",
       "1   Highly available Prometheus setup with long te...                  8   \n",
       "2                            Deep Learning for humans                882   \n",
       "3                                 The React Framework               322k   \n",
       "4   The official GitHub mirror of the Chromium source                  -   \n",
       "5   Libraries and tools to perform fully homomorph...                  -   \n",
       "6   This repository contains all the DSA (Data-Str...                  -   \n",
       "7                          【编程随想】收藏的电子书清单（多个学科，含下载链接）                  -   \n",
       "8   Collection of malware source code for a variet...                  -   \n",
       "9   梦弘浏览器 自主研发版本 - 完全自主研发，打破国外垄断，比 Chrome 快 600%。缺...                  -   \n",
       "10  A long list of (advanced) JavaScript questions...                  -   \n",
       "11  A collection of modern/faster/saner alternativ...                  -   \n",
       "12  30 days of JavaScript programming challenge is...                  -   \n",
       "13  A collection of scripts for activating Microso...                  -   \n",
       "14  A collection of inspiring lists, manuals, chea...                  -   \n",
       "15      The official project of SimSwap (ACM MM 2020)                  -   \n",
       "16                       【编程随想】整理的《太子党关系网络》，专门揭露赵国的权贵                  -   \n",
       "17  Cloud-Native Neural Search Framework for Any K...                 97   \n",
       "18                Use Turbo in your Ruby on Rails app                  -   \n",
       "19  Seata is an easy-to-use, high-performance, ope...                161   \n",
       "20  An open-source NLP research library, built on ...                238   \n",
       "21           beautiful neovim setup configured in lua                  -   \n",
       "22                     Documentation for ASP.NET Core              1,421   \n",
       "23     PyTorch Tutorial for Deep Learning Researchers                  -   \n",
       "24  Keeps your screen real-estate clean with refin...                  -   \n",
       "\n",
       "       Language_used  \n",
       "0               Rust  \n",
       "1                 Go  \n",
       "2             Python  \n",
       "3         JavaScript  \n",
       "4                  -  \n",
       "5                C++  \n",
       "6   Jupyter Notebook  \n",
       "7                  -  \n",
       "8           Assembly  \n",
       "9                  C  \n",
       "10                 -  \n",
       "11                 -  \n",
       "12        JavaScript  \n",
       "13         Batchfile  \n",
       "14                 -  \n",
       "15            Python  \n",
       "16            Python  \n",
       "17            Python  \n",
       "18        JavaScript  \n",
       "19              Java  \n",
       "20            Python  \n",
       "21               Lua  \n",
       "22                C#  \n",
       "23            Python  \n",
       "24                C#  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Github=pd.DataFrame({})\n",
    "Github['Repository_title']=Repository_title\n",
    "Github['Repository_description']=Repository_description\n",
    "Github['Contributors_count']=Contributors_count\n",
    "Github['Language_used']=Language_used\n",
    "Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6th Question."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify serach url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now From the home page we have to click on the charts option then hot 100-page link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will click on charts option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts=driver.find_element_by_xpath(\"(//div[@class='header__main-menu__wrapper flex--grow']/ul/li[1]/a)[2]\")\n",
    "charts.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will select hot 100 page link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//div[@class='charts-landing__info--top charts-landing__info--top--hot-100']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will scrap the required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#song name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "song=driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[1]\")\n",
    "song_name=[]\n",
    "for i in song:\n",
    "    song_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Artist name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist=driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[2]\")\n",
    "artist_name=[]\n",
    "for i in artist:\n",
    "    artist_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last week rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_week=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "last_week_rank=[]\n",
    "for i in last_week:\n",
    "    last_week_rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Peak rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "peak_rank=[]\n",
    "for i in peak:\n",
    "    peak_rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "board=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "weeks_on_board=[]\n",
    "for i in board:\n",
    "    weeks_on_board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will creat datframe for the scrapped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Things A Man Oughta Know</td>\n",
       "      <td>Lainey Wilson</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Country Again</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Drunk (And I Don't Wanna Go Home)</td>\n",
       "      <td>Elle King &amp; Miranda Lambert</td>\n",
       "      <td>92</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>If You Want To</td>\n",
       "      <td>Lil Baby &amp; Lil Durk</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeing Green</td>\n",
       "      <td>Nicki Minaj, Drake &amp; Lil Wayne</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song_name  \\\n",
       "0                              Butter   \n",
       "1                            Good 4 U   \n",
       "2                          Levitating   \n",
       "3                             Peaches   \n",
       "4                 Leave The Door Open   \n",
       "..                                ...   \n",
       "95           Things A Man Oughta Know   \n",
       "96                      Country Again   \n",
       "97  Drunk (And I Don't Wanna Go Home)   \n",
       "98                     If You Want To   \n",
       "99                       Seeing Green   \n",
       "\n",
       "                                       Artist_name Last_week_rank Peak_rank  \\\n",
       "0                                              BTS              1         1   \n",
       "1                                   Olivia Rodrigo              2         1   \n",
       "2                        Dua Lipa Featuring DaBaby              3         2   \n",
       "3   Justin Bieber Featuring Daniel Caesar & Giveon              6         1   \n",
       "4         Silk Sonic (Bruno Mars & Anderson .Paak)              4         1   \n",
       "..                                             ...            ...       ...   \n",
       "95                                   Lainey Wilson             93        93   \n",
       "96                                    Thomas Rhett             89        73   \n",
       "97                     Elle King & Miranda Lambert             92        79   \n",
       "98                             Lil Baby & Lil Durk              -        99   \n",
       "99                  Nicki Minaj, Drake & Lil Wayne             67        12   \n",
       "\n",
       "   Weeks_on_board  \n",
       "0               3  \n",
       "1               4  \n",
       "2              36  \n",
       "3              12  \n",
       "4              14  \n",
       "..            ...  \n",
       "95              4  \n",
       "96              6  \n",
       "97              7  \n",
       "98              1  \n",
       "99              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BillBorad=pd.DataFrame({})\n",
    "BillBorad['Song_name']=song_name\n",
    "BillBorad['Artist_name']=artist_name\n",
    "BillBorad['Last_week_rank']=last_week_rank\n",
    "BillBorad['Peak_rank']=peak_rank\n",
    "BillBorad['Weeks_on_board']=weeks_on_board\n",
    "BillBorad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7th Question."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify search url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now From  homepage click on the recruiters option and  on the search pane type Data science and click on search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli=driver.find_element_by_xpath(\"//ul[@class='midSec menu']/li[2]/a/div\")\n",
    "cli.click()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#After we click we can see that the new window (child window) opened for recruiters page.\n",
    "#Let us  grab the current window handle id with the help of current_window_handle method.\n",
    "#Then switch to that window with switch_to_window() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get current window handle\n",
    "p = driver.current_window_handle\n",
    "#get first child window\n",
    "chwnd = driver.window_handles\n",
    "for w in chwnd:\n",
    "   #switch focus to child window\n",
    "   if(w!=p):\n",
    "        driver.switch_to.window(w)\n",
    "        break\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now enter Data Sceience on serach field with send_keys option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "se=driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "se.send_keys(\"Data science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt=driver.find_element_by_id(\"qsbFormBtn\")\n",
    "bt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will scrap the required data. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aakash Harit',\n",
       " 'shravan Kumar Gaddam',\n",
       " 'MARSIAN Technologies LLP',\n",
       " 'Anik Agrawal',\n",
       " 'subhas patel',\n",
       " 'Abhishek - Only Analytics Hiring - India and',\n",
       " 'Institute for Financial Management and Resear',\n",
       " 'Balu Ramesh',\n",
       " 'Asif Lucknowi',\n",
       " 'InstaFinancials',\n",
       " 'Kalpana Dumpala',\n",
       " 'Mubarak',\n",
       " 'Kushal Rastogi',\n",
       " 'Ruchi Dhote',\n",
       " 'Mahesh Babu Channa',\n",
       " 'Kapil Devang',\n",
       " 'Manisha Yadav',\n",
       " 'Riya Rajesh',\n",
       " 'Rashmi Bhattacharjee',\n",
       " 'Faizan Kareem',\n",
       " 'Rithika dadwal',\n",
       " 'Azahar Shaikh',\n",
       " 'Sandhya Khandagale',\n",
       " 'Shaun Rao',\n",
       " 'Manas',\n",
       " 'kumar',\n",
       " 'Sunil Vedula',\n",
       " 'Rajat Kumar',\n",
       " 'Priya Khare',\n",
       " 'Dhruv Dev Dubey',\n",
       " 'Jayanth N',\n",
       " 'Radha Manivasagam',\n",
       " 'Prateek Kumar',\n",
       " 'Amit Sharma',\n",
       " 'Kanan',\n",
       " 'Shashikant Chaudhary',\n",
       " 'Brad',\n",
       " 'Rutuja Pawar',\n",
       " 'Madhusudhan Sridhar',\n",
       " 'Ankit Sinha',\n",
       " 'Gaurav Chouhan',\n",
       " 'Rashi Kacker',\n",
       " 'Ashwini',\n",
       " 'Balaji Kolli',\n",
       " 'Rajani Nagaraj',\n",
       " 'ROHIT Kumar',\n",
       " 'Amir Chowdhury',\n",
       " 'Shailja Mishra',\n",
       " 'Sunny Sharma',\n",
       " 'Sagar Lama']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=driver.find_elements_by_xpath(\"//p[@class='highlightable']/a/span\")\n",
    "Name=[]\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "Name"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HR Manager',\n",
       " 'Company Recruiter',\n",
       " 'Company HR',\n",
       " 'Company Recruiter',\n",
       " 'Founder CEO',\n",
       " 'Recruitment Lead Consultant',\n",
       " 'Programme Manager',\n",
       " 'HR Administrator',\n",
       " 'Director',\n",
       " 'Human Resource',\n",
       " 'Executive Hiring',\n",
       " 'Company HR',\n",
       " 'Company HR',\n",
       " 'Senior Executive Talent Acquisition',\n",
       " 'HR Team Lead',\n",
       " 'HR Manager',\n",
       " 'HR Executive',\n",
       " 'Manager Talent Acquisition',\n",
       " 'HR Head',\n",
       " 'HR MANAGER',\n",
       " 'HR Recruiter',\n",
       " 'Company Recruiter',\n",
       " 'HR Recruiter',\n",
       " 'Manager Human Resources',\n",
       " 'Lead Talent acquisition',\n",
       " 'Proprietor',\n",
       " 'CEO',\n",
       " 'Founder CEO',\n",
       " 'Senior Manager',\n",
       " 'Company Recruitment Head',\n",
       " 'Project Manager',\n",
       " 'HR Executive',\n",
       " 'Head',\n",
       " 'Consultant',\n",
       " 'senior technology instructor',\n",
       " 'HR Recruiter/HR Excutive',\n",
       " 'Manager, Technical Recruiting',\n",
       " 'Technical Recruiter',\n",
       " 'Erp Implementer',\n",
       " 'Head Analytics',\n",
       " 'Chief Technical Officer',\n",
       " 'Sr Product Manager',\n",
       " 'Director Global Delivery',\n",
       " 'Co Founder',\n",
       " 'HR Manager',\n",
       " 'Architect',\n",
       " 'Managing Partner',\n",
       " 'HR Manager',\n",
       " 'Managing Director - HR',\n",
       " 'Company HR Manager']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desg=driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\")\n",
    "Designation=[]\n",
    "for i in desg:\n",
    "    Designation.append(i.text)\n",
    "Designation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science Network',\n",
       " 'Shore Infotech India Pvt. Ltd',\n",
       " 'MARSIAN Technologies LLP',\n",
       " 'Enerlytics Software Solutions Pvt Ltd',\n",
       " 'LibraryXProject',\n",
       " 'Apidel Technologies Division of Transpower',\n",
       " 'IFMR',\n",
       " 'Techvantage Systems Pvt Ltd',\n",
       " 'Weupskill- Live Wire India',\n",
       " 'CBL Data Science Private Limited',\n",
       " 'Innominds Software',\n",
       " 'MoneyTap',\n",
       " 'QuantMagnum Technologies Pvt. Ltd.',\n",
       " 'Bristlecone India Ltd',\n",
       " 'SocialPrachar.com',\n",
       " 'BISP Solutions',\n",
       " 'Easi Tax',\n",
       " 'Novelworx Digital Solutions',\n",
       " 'AXESTRACK SOFTWARE SOLUTIONS PRIVATE...',\n",
       " 'FirstTech Consaltants Pvt.Ltd',\n",
       " 'Affine Analytics',\n",
       " 'NEAL ANALYTICS SERVICES PVT LTD',\n",
       " 'Compumatrice Multimedia Pvt Ltd',\n",
       " 'Exela Technologies',\n",
       " 'Autumn Leaf Consulting Services Private...',\n",
       " 'trainin',\n",
       " 'Nanoprecise Sci Corp',\n",
       " 'R.S Consultancy &amp; Services',\n",
       " 'Independent Consultant',\n",
       " 'Confidential',\n",
       " 'Dollarbird Information Services Pvt, Ltd',\n",
       " 'Techcovery',\n",
       " 'Trisect',\n",
       " 'ASCO consulting',\n",
       " 'NY INST',\n",
       " '3D India Staffing Research &amp; Consulting...',\n",
       " 'O.C. Tanner',\n",
       " 'Demand Matrix',\n",
       " 'MADHUSUDHAN SRIDHAR',\n",
       " 'Suntech Global',\n",
       " 'Strategic Consulting Lab',\n",
       " 'Impel Labs Pvt. Ltd.',\n",
       " 'MRP Advisers',\n",
       " 'Saras Solutions India Pvt Ltd',\n",
       " 'WildJasmine',\n",
       " 'LNT Private Limited',\n",
       " 'Granular.ai',\n",
       " 'Certybox Pvt.Ltd.',\n",
       " 'Western Service Providers',\n",
       " 'AdView']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp=driver.find_elements_by_xpath(\"//a[@class='ellipsis'][2]\")\n",
    "Company=[]\n",
    "for i in comp:\n",
    "    Company.append(i.text)\n",
    "Company"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Skills they hire for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classic ASP Developer, Internet Marketing Professional, Data Science SME, Content Writers, SEO Professional, Revenue Professional',\n",
       " '.Net, Java, Data Science, Linux Administration, Sql Server Development, Winforms, Wcf Services, Wpf, Telecom Engineering, Technical Management, Software',\n",
       " 'Data Science, Artificial Intelligence, Machine Learning, Business Analytics',\n",
       " 'Mean Stack, javascript, angularjs, mongodb, Web Services, rest, express, Node.js, Big Data, iot, Data Science, Cloud Computing, saas, Aws',\n",
       " 'Hadoop, Spark, Digital Strategy, Data Architecture, Command Center, Cdp, Dmp, Kafka, Data Science, Data Analysis, Big Data Analytics, Real Time Analysis, SQL',\n",
       " 'Analytics, Business Intelligence, Business Analytics, Predictive Modeling, Predictive Analytics, Data Science, Data Analysis, Data Analytics, Big Data, Big',\n",
       " 'Data Science',\n",
       " 'Machine Learning, algorithms, Go Getter, Computer Science, spark, Big Data, hdfs, sql, cassandra, hadoop, python, scala, java, Data Science, Front End',\n",
       " 'Technical Training, Software Development, Presentation Skills, B.tech, M.tech, B.e., mca, msc, Computer Science, freshers, jobs in indore, Data Science, itil',\n",
       " 'Software Development, It Sales, Account Management, Data Analysis, Customer Service, Sr, Software Engineering, Mvc, Ajax, Asp.net, Html, C#, Javascript',\n",
       " 'Qa, Ui/ux, Java Developer, Java Architect, C++/qt, Php, Lamp, Api, J2ee, Java, Soa, Esb, Middleware, Bigdata Achitect, Hadoop Architect, Deep',\n",
       " 'Business Intelligence, Data Warehousing, Data Science, Business Analytics, Customer Support, Business Reporting, Bi',\n",
       " 'Office Administration, Hr Administration, telecalling, client relationship management, Client Acquisition, Sales, Reception, HR, Recruitment, Onboarding, Human',\n",
       " 'Qlikview, Qlik Sense, Microsoft Azure, Power Bi, Data Science, Machine Learning',\n",
       " 'Social Media, digital media maketing, seo, smm, smo, sem, Content Wirting, social media marketing, social media manager, digital media marketing manager',\n",
       " 'Big Data, Hadoop, Data Analytics, Data Science',\n",
       " 'Telecalling, Client Interaction, Marketing, Research, Web Development, Social Media Marketing, Data Entry Operation, Excel, Ms Office, Invoicing',\n",
       " 'Data Science',\n",
       " 'Corporate Sales, Software Development, Software Sales, Marketing, Creative Designing, Corporate Planning, Senior Management, Crm, Client Relationship',\n",
       " 'Data Analytics, Data Science, Machine Learning, Deep Learning, Nlp, Data Mining, Python, R, Database Administration, Text Mining',\n",
       " 'Data Science, Machine Learning, Python, R, Deep Learning, Big Data, Hadoop',\n",
       " 'Data Science, Artificial Intelligence, Machine Learning, Data Analytics',\n",
       " 'Big Data, Data Science, Artificial Intelligence, Hadoop, Ui Development, Php, Freelancing, .Net, Software Testing, Sap, Leadership Hiring',\n",
       " 'Java, Net, Angularjs, Hr, Infrastructure, Management, Project Management, Business Analysis, Data Science, Information Technology, Technology',\n",
       " 'Software Architecture, Vp Engineering, Product Management, analytics, Data Science, Node.js, Principal Engineer, Big Data, python, angularjs, React.js',\n",
       " 'Data Science, Hadoop, Rpas, Devops, Python, Aws, Teaching, Big Data',\n",
       " 'Signal Processing, Machine Learning, Neural Networks, Data Science, Predictive Analytics, Time Series Analysis, Data Visualization, Technical Leadership, Data',\n",
       " 'Web Technologies, Project Management, Software Architecture, Data Science, Object Oriented Programming, Computer Science, Electrical Engineering, Architecture',\n",
       " 'Data Science, Artificial Intelligence, analytics, Business Intelligence, python, tableau, Power Bi, qlikview, sql, Data Warehousing, Data Visualization',\n",
       " 'Server Administartion, Verilog, Vhdl, Digital Marketing, Market Research, Property Research, Legal, It And Non It Recruitment, Logistics, Supply Chain, Bfsi',\n",
       " 'Data Analytics, Managed Services, Team Leading, python, Machine Learning, Google Analytics, Dmp, Aws, Campaign Analytics, Digital Campaigns, Audience',\n",
       " 'Python, Artificial Intelligence, Machine Learning, Data Science',\n",
       " 'Java, Python, Angularjs, Software Testing, Machine Learning, Data Science, Javascript, Django, React.js, Node.js, Augmented Reality, Virtual Reality, Advanced',\n",
       " 'Machine Learning, Artificial Intelligence, Data Science, Software Engineering, Software Development, Graduate Engineer Trainee, Fresher, Data Analytics, Java',\n",
       " 'C, C++, Artificial Intelligence, Python, Php, Web Development, Matlab, Data Science, Augmented Reality, C C++',\n",
       " 'Relationship Management, Retail Sales, Private Banking, Mutual Funds, NISM, Equity, Finance, Financial Products, Financial Services, Verbal, Written',\n",
       " 'Data Science, Software Engineering',\n",
       " 'Data Science, Big Data Analytics, Digital Marketing, Content Writing, Ui Development, Database Development, Qa Automation, Python, Project Management',\n",
       " 'Data Science, Recruitment, Salary',\n",
       " 'B.Tech, Tableau, Statistics, R, Analytics, Time Series, Data Science, Business Solutions, SQL, Technical Skills, SSAS, SQL Server, Analysis Services, Qlikview',\n",
       " 'Software Development, Business Intelligence, Big Data Analytics, Database Administration, Data Science, Microsoft Azure, Spark, Cassandra, Object Oriented',\n",
       " 'Data Science, Node.js, Angularjs',\n",
       " 'Data Science, Media Marketing, Resource Planning, Managed Services, Display Advertising, Machine Learning, Python, Etl, Sql',\n",
       " 'Data Analysis, Learning, Data Science, Computer Science, Communication Skills',\n",
       " 'Java, Hadoop, R, Machine Learning, Spark, Flume, Hdfs, Data Mining, Sas, Big, Data Science, Cloudera, Impala, Bigdata',\n",
       " 'Software Development, Core Java, Unit Testing, Customer Experience, Problem Solving, Communication Skills, Mysql, Data Science, Sales Management, Analytics',\n",
       " 'Machine Learning, Data Science, Product Management, New Product, Data Analysis, Computer Vision, Deep Learning, Python, Remote Sensing',\n",
       " 'consulting, Education Counseling, Educational Sales, Institutional Sales, pmp, Data Science, Business Development, Revenue Generation, Sales Achievement, new',\n",
       " 'Software Professionals, Engineering, Technical Management, Financial Management, Human Resource Management, Banking, Google Adwords, Business Analysis, It',\n",
       " 'Full Stack Developers, Product Manager, Data Science Engineer, Publishers Sales Manager']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill=driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\")\n",
    "Skills_required=[]\n",
    "for i in skill:\n",
    "    Skills_required.append(i.text)\n",
    "Skills_required"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Ahmedabad',\n",
       " 'UK - (london)',\n",
       " 'Vadodara / Baroda',\n",
       " 'Chennai',\n",
       " 'Trivandrum',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Pune',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bhopal',\n",
       " 'Navi Mumbai',\n",
       " 'Cochin',\n",
       " 'Delhi',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Delhi',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mysoru / Mysore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'Chennai',\n",
       " 'Aligarh',\n",
       " 'Salt Lake City',\n",
       " 'Pune',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Indore',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'MYSORE',\n",
       " 'Hyderabad / Secunderabad',\n",
       " 'Bengaluru / Bangalore',\n",
       " 'Mumbai',\n",
       " 'Noida',\n",
       " 'Mumbai',\n",
       " 'Bengaluru / Bangalore']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")\n",
    "Location=[]\n",
    "for i in place:\n",
    "    Location.append(i.text)\n",
    "Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8th Question."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-\n",
    "compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Firefox('E:\\geckodriver-v0.29.1-win64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify search url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have to scrap data of highest selling Novels. On the website we can see that the data is tabular form.\n",
    "#with the help of beautifulsoup we will extract the whole table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html')\n",
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will load the extracted data by using pandas.read_html(because it is is html format) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(str(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[0] #Here is the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5094805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4475152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4200654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4179479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3758936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                              Title            Author  \\\n",
       "0     1                                  Da Vinci Code,The        Brown, Dan   \n",
       "1     2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2     3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3     4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4     5                               Fifty Shades of Grey      James, E. L.   \n",
       "..  ...                                                ...               ...   \n",
       "95   96                                          Ghost,The    Harris, Robert   \n",
       "96   97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97   98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98   99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sales        Publisher                        Genre  \n",
       "0       5094805       Transworld  Crime, Thriller & Adventure  \n",
       "1       4475152       Bloomsbury           Children's Fiction  \n",
       "2       4200654       Bloomsbury           Children's Fiction  \n",
       "3       4179479       Bloomsbury           Children's Fiction  \n",
       "4       3758936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95       807311     Random House   General & Literary Fiction  \n",
       "96       794201          Penguin        Food & Drink: General  \n",
       "97       792187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98       791507            Orion           Biography: General  \n",
       "99       791095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will change the column names as per the required names.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'Title', 'Author', 'Volume Sales', 'Publisher', 'Genre'], dtype='object')"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naniii\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns = {'Title':'Book_Name'}, inplace = True)\n",
    "df.rename(columns = {'Author':'Author_Name'}, inplace = True)\n",
    "df.rename(columns = {'Volume Sales':'Volumes_sold'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5094805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4475152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4200654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4179479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3758936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                                  Book_Name    Author_Name Volumes_sold  \\\n",
       "0    1                          Da Vinci Code,The     Brown, Dan      5094805   \n",
       "1    2       Harry Potter and the Deathly Hallows  Rowling, J.K.      4475152   \n",
       "2    3   Harry Potter and the Philosopher's Stone  Rowling, J.K.      4200654   \n",
       "3    4  Harry Potter and the Order of the Phoenix  Rowling, J.K.      4179479   \n",
       "4    5                       Fifty Shades of Grey   James, E. L.      3758936   \n",
       "\n",
       "      Publisher                        Genre  \n",
       "0    Transworld  Crime, Thriller & Adventure  \n",
       "1    Bloomsbury           Children's Fiction  \n",
       "2    Bloomsbury           Children's Fiction  \n",
       "3    Bloomsbury           Children's Fiction  \n",
       "4  Random House              Romance & Sagas  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9th Question."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify search url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap the required data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name of the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "Name=[]\n",
    "for i in mov:\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Year Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/span[2]\")\n",
    "Year_span=[]\n",
    "for i in year:\n",
    "    Year_span.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Genere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "genere=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "Genere=[]\n",
    "for i in genere:\n",
    "    Genere.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Run Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "time=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "Run_Time=[]\n",
    "for i in time:\n",
    "    Run_Time.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "Rating=[]\n",
    "for i in rating:\n",
    "    Rating.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "vot=driver.find_elements_by_name(\"nv\")\n",
    "Votes=[]\n",
    "for i in vot:\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genere</th>\n",
       "      <th>Run_Time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,824,188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>864,449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>874,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>224,155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>167,874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>34,904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>191,553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                    Genere  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_Time Rating      Votes  \n",
       "0    57 min    9.3  1,824,188  \n",
       "1    51 min    8.7    864,449  \n",
       "2    44 min    8.2    874,790  \n",
       "3    60 min    7.6    262,785  \n",
       "4    43 min    7.6    224,155  \n",
       "..      ...    ...        ...  \n",
       "95   42 min    7.5     44,588  \n",
       "96   50 min    7.8     55,093  \n",
       "97   42 min      8    167,874  \n",
       "98   45 min    7.1     34,904  \n",
       "99  572 min    8.6    191,553  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb=pd.DataFrame({})\n",
    "imdb['Name']=Name\n",
    "imdb['Year_span']=Year_span\n",
    "imdb['Genere']=Genere\n",
    "imdb['Run_Time']=Run_Time\n",
    "imdb['Rating']=Rating\n",
    "imdb['Votes']=Votes\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10th Question"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify search URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the home page we have to select the Show All Dataset page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "ber=driver.find_element_by_xpath(\"//span[@class='normal']/b/a\")\n",
    "ber.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets the extract the required data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DataSet_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=driver.find_elements_by_xpath(\"//p[@class='normal']/b/a\")\n",
    "DataSet_Name=[]\n",
    "for i in Name:\n",
    "    DataSet_Name.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "year=driver.find_elements_by_xpath(\"//td[7]/p[@class='normal']\")\n",
    "Year=[]\n",
    "for i in year:\n",
    "    Year.append(i.text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the remaining data we will use exception.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will get the urls of each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur=driver.find_elements_by_xpath(\"//p[@class='normal']/b/a\")\n",
    "url=[]\n",
    "for i in ur:\n",
    "    url.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will handle the remaining data with exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    driver.get(i)\n",
    "    \n",
    "    try:\n",
    "        noof=driver.find_element_by_xpath(\"//tr[1]/td[2]/p[@class='normal']\")\n",
    "        Data_type.append(noof.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append(\"-\")\n",
    "    try:\n",
    "        ret=driver.find_element_by_xpath(\"//tr[1]/td[4]/p[@class='normal']\")\n",
    "        No_of_instances.append(ret.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append(\"-\")      \n",
    "        \n",
    "    try:\n",
    "        oof=driver.find_element_by_xpath(\"//tr[3]/td[2]/p[@class='normal']\")\n",
    "        Task.append(oof.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append(\"-\")\n",
    "    try:\n",
    "        et=driver.find_element_by_xpath(\"//tr[2]/td[2]/p[@class='normal']\")\n",
    "        Attribute_type.append(et.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append(\"-\") \n",
    "        \n",
    "    try:\n",
    "        vt=driver.find_element_by_xpath(\"//tr[2]/td[4]/p[@class='normal']\")\n",
    "        No_of_attribute.append(vt.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attribute.append(\"-\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's create data frame for all scrapped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet_Name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         DataSet_Name     Data_type                 Task  \\\n",
       "0                             Abalone  Multivariate       Classification   \n",
       "1                               Adult  Multivariate       Classification   \n",
       "2                           Annealing  Multivariate       Classification   \n",
       "3        Anonymous Microsoft Web Data           N/A  Recommender-Systems   \n",
       "4                          Arrhythmia  Multivariate       Classification   \n",
       "..                                ...           ...                  ...   \n",
       "583  in-vehicle coupon recommendation  Multivariate       Classification   \n",
       "584               Gait Classification  Multivariate       Classification   \n",
       "585         Wikipedia Math Essentials   Time-Series           Regression   \n",
       "586         Wikipedia Math Essentials   Time-Series           Regression   \n",
       "587      Synchronous Machine Data Set  Multivariate           Regression   \n",
       "\n",
       "                 Attribute_type No_of_instances No_of_attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8  1995   \n",
       "1          Categorical, Integer           48842              14  1996   \n",
       "2    Categorical, Integer, Real             798              38         \n",
       "3                   Categorical           37711             294  1998   \n",
       "4    Categorical, Integer, Real             452             279  1998   \n",
       "..                          ...             ...             ...    ...  \n",
       "583                         N/A           12684              23  2020   \n",
       "584                        Real              48             321  2020   \n",
       "585                        Real             731            1068  2021   \n",
       "586                        Real             731            1068  2021   \n",
       "587                        Real             557               5  2021   \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCI=pd.DataFrame({})\n",
    "UCI['DataSet_Name']=DataSet_Name\n",
    "UCI['Data_type']=Data_type\n",
    "UCI['Task']=Task\n",
    "UCI['Attribute_type']=Attribute_type\n",
    "UCI['No_of_instances']=No_of_instances\n",
    "UCI['No_of_attribute']=No_of_attribute\n",
    "UCI['Year']=Year\n",
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE END OF THE ASSIGNMENT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
